{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8f52ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8857/3777615979.py:1: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77243f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import fashion_mnist\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fashion_mnist=keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9dc05906",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def relu_derivative(x):\n",
    "    return x > 0\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(s):\n",
    "    return s * (1 - s)\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def tanh_derivative(x):\n",
    "    return 1 - np.tanh(x)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75cdd08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, layer_sizes, activation='relu'):\n",
    "        self.layer_sizes = layer_sizes\n",
    "        self.activation, self.activation_derivative = self.set_activation_functions(activation)\n",
    "        self.parameters = self.initialize_parameters()\n",
    "\n",
    "    def set_activation_functions(self, activation):\n",
    "        if activation == 'relu':\n",
    "            return relu, relu_derivative\n",
    "        elif activation == 'sigmoid':\n",
    "            return sigmoid, sigmoid_derivative\n",
    "        elif activation == 'tanh':\n",
    "            return tanh, tanh_derivative\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported activation function\")\n",
    "            \n",
    "    def initialize_parameters(self):\n",
    "        parameters = {}\n",
    "        for l in range(1, len(self.layer_sizes)):\n",
    "            parameters['W' + str(l)] = np.random.randn(self.layer_sizes[l], self.layer_sizes[l-1]) * 0.01\n",
    "            parameters['b' + str(l)] = np.zeros((self.layer_sizes[l], 1))\n",
    "        return parameters\n",
    "    \n",
    "    def softmax(self, Z):\n",
    "        expZ = np.exp(Z - np.max(Z))\n",
    "        return expZ / expZ.sum(axis=0, keepdims=True)\n",
    "    \n",
    "    def compute_loss(self, Y, Y_hat):\n",
    "        m = Y.shape[1]\n",
    "        loss = -np.sum(Y * np.log(Y_hat + 1e-9)) / m\n",
    "        return loss\n",
    "    \n",
    "    def forward_propagation(self, X):\n",
    "        caches = {}\n",
    "        H = X\n",
    "        L = len(self.parameters) // 2\n",
    "        \n",
    "        for l in range(1, L):\n",
    "            H_prev = H\n",
    "            A = np.dot(self.parameters['W' + str(l)], H_prev) + self.parameters['b' + str(l)]\n",
    "            H = self.activation(A) \n",
    "            caches['A' + str(l)] = A\n",
    "            caches['H' + str(l)] = H\n",
    "        \n",
    "        AL = np.dot(self.parameters['W' + str(L)], H) + self.parameters['b' + str(L)]\n",
    "        HL = self.softmax(AL)\n",
    "        caches['A' + str(L)] = AL\n",
    "        caches['H' + str(L)] = HL\n",
    "        return HL, caches\n",
    "    \n",
    "    def backpropagation(self, X, Y, caches):\n",
    "        grads = {}\n",
    "        L = len(self.parameters) // 2 # Number of layers\n",
    "        m = X.shape[1]\n",
    "        Y = Y.reshape(caches['H' + str(L)].shape) # Ensure same shape as output layer\n",
    "\n",
    "        # Initializing backpropagation and Output layer gradient\n",
    "        dAL = caches['H' + str(L)] - Y\n",
    "        grads[\"dW\" + str(L)] = 1./m * np.dot(dAL, caches['H' + str(L-1)].T)\n",
    "        grads[\"db\" + str(L)] = 1./m * np.sum(dAL, axis=1, keepdims=True)\n",
    "\n",
    "        for l in reversed(range(1, L)):\n",
    "            dH = np.dot(self.parameters[\"W\" + str(l+1)].T, dAL) # dH_prev\n",
    "            dA = self.activation_derivative(caches['A' + str(l)]) * dH # Element wise multiplication between 2 vectors # <-----------------------------------------\n",
    "            if l > 1:\n",
    "                grads[\"dW\" + str(l)] = 1./m * np.dot(dA, caches['H' + str(l-1)].T)\n",
    "            else: # For the first hidden layer, use X as A0\n",
    "                grads[\"dW\" + str(l)] = 1./m * np.dot(dA, X.T)\n",
    "            grads[\"db\" + str(l)] = 1./m * np.sum(dA, axis=1, keepdims=True)\n",
    "            dAL = dA  # For the next iteration. Prepare dAL for next layer (if not the first layer)\n",
    "\n",
    "        return grads\n",
    "    \n",
    "    def update_parameters(self, grads, learning_rate):\n",
    "        L = len(self.parameters) // 2\n",
    "        for l in range(L):\n",
    "            self.parameters[\"W\" + str(l+1)] -= learning_rate * grads[\"dW\" + str(l+1)]\n",
    "            self.parameters[\"b\" + str(l+1)] -= learning_rate * grads[\"db\" + str(l+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7201b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_labels_to_one_hot(labels, classes):\n",
    "    return np.eye(classes)[labels].T\n",
    "\n",
    "def preprocess_data(train_images, train_labels, test_images, test_labels):\n",
    "    X_train = train_images.reshape(train_images.shape[0], -1).T / 255.\n",
    "    X_test = test_images.reshape(test_images.shape[0], -1).T / 255.\n",
    "    \n",
    "    Y_train = convert_labels_to_one_hot(train_labels, 10)\n",
    "    Y_test = convert_labels_to_one_hot(test_labels, 10)\n",
    "    \n",
    "    return X_train, Y_train, X_test, Y_test  \n",
    "\n",
    "def plot_training_loss_and_test_acc(epochs, traing_loss, test_accuracy):\n",
    "    epochs_range = list(range(0, epochs))\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(epochs_range, traing_loss, label='Training Loss')\n",
    "    plt.plot(epochs_range, test_accuracy, label='Test Accuracy')\n",
    "    plt.title('Training Loss and Test Accuracy over Epochs')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss/Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4749d5d9",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Training loss: 2.301969\n",
      "Test accuracy : 0.1375\n",
      "\n",
      "Epoch 1, Training loss: 2.301784\n",
      "Test accuracy : 0.1395\n",
      "\n",
      "Epoch 2, Training loss: 2.301600\n",
      "Test accuracy : 0.1418\n",
      "\n",
      "Epoch 3, Training loss: 2.301416\n",
      "Test accuracy : 0.1453\n",
      "\n",
      "Epoch 4, Training loss: 2.301233\n",
      "Test accuracy : 0.1479\n",
      "\n",
      "Epoch 5, Training loss: 2.301049\n",
      "Test accuracy : 0.1504\n",
      "\n",
      "Epoch 6, Training loss: 2.300865\n",
      "Test accuracy : 0.152\n",
      "\n",
      "Epoch 7, Training loss: 2.300682\n",
      "Test accuracy : 0.1546\n",
      "\n",
      "Epoch 8, Training loss: 2.300498\n",
      "Test accuracy : 0.1586\n",
      "\n",
      "Epoch 9, Training loss: 2.300314\n",
      "Test accuracy : 0.1628\n",
      "\n",
      "Epoch 10, Training loss: 2.300130\n",
      "Test accuracy : 0.1679\n",
      "\n",
      "Epoch 11, Training loss: 2.299946\n",
      "Test accuracy : 0.173\n",
      "\n",
      "Epoch 12, Training loss: 2.299761\n",
      "Test accuracy : 0.1781\n",
      "\n",
      "Epoch 13, Training loss: 2.299576\n",
      "Test accuracy : 0.1838\n",
      "\n",
      "Epoch 14, Training loss: 2.299390\n",
      "Test accuracy : 0.1886\n",
      "\n",
      "Epoch 15, Training loss: 2.299204\n",
      "Test accuracy : 0.1952\n",
      "\n",
      "Epoch 16, Training loss: 2.299017\n",
      "Test accuracy : 0.2003\n",
      "\n",
      "Epoch 17, Training loss: 2.298829\n",
      "Test accuracy : 0.2071\n",
      "\n",
      "Epoch 18, Training loss: 2.298641\n",
      "Test accuracy : 0.214\n",
      "\n",
      "Epoch 19, Training loss: 2.298451\n",
      "Test accuracy : 0.2207\n",
      "\n",
      "Epoch 20, Training loss: 2.298261\n",
      "Test accuracy : 0.2254\n",
      "\n",
      "Epoch 21, Training loss: 2.298070\n",
      "Test accuracy : 0.2299\n",
      "\n",
      "Epoch 22, Training loss: 2.297878\n",
      "Test accuracy : 0.2336\n",
      "\n",
      "Epoch 23, Training loss: 2.297684\n",
      "Test accuracy : 0.2358\n",
      "\n",
      "Epoch 24, Training loss: 2.297490\n",
      "Test accuracy : 0.2403\n",
      "\n",
      "Epoch 25, Training loss: 2.297294\n",
      "Test accuracy : 0.243\n",
      "\n",
      "Epoch 26, Training loss: 2.297097\n",
      "Test accuracy : 0.2448\n",
      "\n",
      "Epoch 27, Training loss: 2.296898\n",
      "Test accuracy : 0.248\n",
      "\n",
      "Epoch 28, Training loss: 2.296698\n",
      "Test accuracy : 0.2498\n",
      "\n",
      "Epoch 29, Training loss: 2.296497\n",
      "Test accuracy : 0.2506\n",
      "\n",
      "Epoch 30, Training loss: 2.296294\n",
      "Test accuracy : 0.2516\n",
      "\n",
      "Epoch 31, Training loss: 2.296089\n",
      "Test accuracy : 0.252\n",
      "\n",
      "Epoch 32, Training loss: 2.295883\n",
      "Test accuracy : 0.2528\n",
      "\n",
      "Epoch 33, Training loss: 2.295675\n",
      "Test accuracy : 0.2514\n",
      "\n",
      "Epoch 34, Training loss: 2.295465\n",
      "Test accuracy : 0.2503\n",
      "\n",
      "Epoch 35, Training loss: 2.295253\n",
      "Test accuracy : 0.2496\n",
      "\n",
      "Epoch 36, Training loss: 2.295039\n",
      "Test accuracy : 0.2494\n",
      "\n",
      "Epoch 37, Training loss: 2.294824\n",
      "Test accuracy : 0.2485\n",
      "\n",
      "Epoch 38, Training loss: 2.294606\n",
      "Test accuracy : 0.2469\n",
      "\n",
      "Epoch 39, Training loss: 2.294385\n",
      "Test accuracy : 0.2462\n",
      "\n",
      "Epoch 40, Training loss: 2.294163\n",
      "Test accuracy : 0.2453\n",
      "\n",
      "Epoch 41, Training loss: 2.293938\n",
      "Test accuracy : 0.2445\n",
      "\n",
      "Epoch 42, Training loss: 2.293711\n",
      "Test accuracy : 0.243\n",
      "\n",
      "Epoch 43, Training loss: 2.293481\n",
      "Test accuracy : 0.2422\n",
      "\n",
      "Epoch 44, Training loss: 2.293248\n",
      "Test accuracy : 0.2403\n",
      "\n",
      "Epoch 45, Training loss: 2.293013\n",
      "Test accuracy : 0.2395\n",
      "\n",
      "Epoch 46, Training loss: 2.292776\n",
      "Test accuracy : 0.2381\n",
      "\n",
      "Epoch 47, Training loss: 2.292535\n",
      "Test accuracy : 0.2363\n",
      "\n",
      "Epoch 48, Training loss: 2.292292\n",
      "Test accuracy : 0.2337\n",
      "\n",
      "Epoch 49, Training loss: 2.292046\n",
      "Test accuracy : 0.2327\n",
      "\n",
      "Epoch 50, Training loss: 2.291796\n",
      "Test accuracy : 0.2317\n",
      "\n",
      "Epoch 51, Training loss: 2.291544\n",
      "Test accuracy : 0.2307\n",
      "\n",
      "Epoch 52, Training loss: 2.291289\n",
      "Test accuracy : 0.2289\n",
      "\n",
      "Epoch 53, Training loss: 2.291030\n",
      "Test accuracy : 0.2267\n",
      "\n",
      "Epoch 54, Training loss: 2.290768\n",
      "Test accuracy : 0.2248\n",
      "\n",
      "Epoch 55, Training loss: 2.290503\n",
      "Test accuracy : 0.2233\n",
      "\n",
      "Epoch 56, Training loss: 2.290234\n",
      "Test accuracy : 0.2217\n",
      "\n",
      "Epoch 57, Training loss: 2.289962\n",
      "Test accuracy : 0.2202\n",
      "\n",
      "Epoch 58, Training loss: 2.289686\n",
      "Test accuracy : 0.2186\n",
      "\n",
      "Epoch 59, Training loss: 2.289407\n",
      "Test accuracy : 0.2167\n",
      "\n",
      "Epoch 60, Training loss: 2.289123\n",
      "Test accuracy : 0.2159\n",
      "\n",
      "Epoch 61, Training loss: 2.288836\n",
      "Test accuracy : 0.2142\n",
      "\n",
      "Epoch 62, Training loss: 2.288545\n",
      "Test accuracy : 0.212\n",
      "\n",
      "Epoch 63, Training loss: 2.288250\n",
      "Test accuracy : 0.2102\n",
      "\n",
      "Epoch 64, Training loss: 2.287951\n",
      "Test accuracy : 0.2093\n",
      "\n",
      "Epoch 65, Training loss: 2.287648\n",
      "Test accuracy : 0.2083\n",
      "\n",
      "Epoch 66, Training loss: 2.287340\n",
      "Test accuracy : 0.2069\n",
      "\n",
      "Epoch 67, Training loss: 2.287028\n",
      "Test accuracy : 0.2051\n",
      "\n",
      "Epoch 68, Training loss: 2.286712\n",
      "Test accuracy : 0.2042\n",
      "\n",
      "Epoch 69, Training loss: 2.286391\n",
      "Test accuracy : 0.2029\n",
      "\n",
      "Epoch 70, Training loss: 2.286066\n",
      "Test accuracy : 0.202\n",
      "\n",
      "Epoch 71, Training loss: 2.285736\n",
      "Test accuracy : 0.2017\n",
      "\n",
      "Epoch 72, Training loss: 2.285402\n",
      "Test accuracy : 0.2007\n",
      "\n",
      "Epoch 73, Training loss: 2.285063\n",
      "Test accuracy : 0.1998\n",
      "\n",
      "Epoch 74, Training loss: 2.284718\n",
      "Test accuracy : 0.1991\n",
      "\n",
      "Epoch 75, Training loss: 2.284369\n",
      "Test accuracy : 0.1979\n",
      "\n",
      "Epoch 76, Training loss: 2.284015\n",
      "Test accuracy : 0.1969\n",
      "\n",
      "Epoch 77, Training loss: 2.283656\n",
      "Test accuracy : 0.1963\n",
      "\n",
      "Epoch 78, Training loss: 2.283291\n",
      "Test accuracy : 0.1959\n",
      "\n",
      "Epoch 79, Training loss: 2.282921\n",
      "Test accuracy : 0.1953\n",
      "\n",
      "Epoch 80, Training loss: 2.282546\n",
      "Test accuracy : 0.1945\n",
      "\n",
      "Epoch 81, Training loss: 2.282165\n",
      "Test accuracy : 0.1936\n",
      "\n",
      "Epoch 82, Training loss: 2.281778\n",
      "Test accuracy : 0.1931\n",
      "\n",
      "Epoch 83, Training loss: 2.281386\n",
      "Test accuracy : 0.1929\n",
      "\n",
      "Epoch 84, Training loss: 2.280988\n",
      "Test accuracy : 0.1923\n",
      "\n",
      "Epoch 85, Training loss: 2.280584\n",
      "Test accuracy : 0.192\n",
      "\n",
      "Epoch 86, Training loss: 2.280174\n",
      "Test accuracy : 0.1919\n",
      "\n",
      "Epoch 87, Training loss: 2.279758\n",
      "Test accuracy : 0.1914\n",
      "\n",
      "Epoch 88, Training loss: 2.279336\n",
      "Test accuracy : 0.1911\n",
      "\n",
      "Epoch 89, Training loss: 2.278908\n",
      "Test accuracy : 0.1908\n",
      "\n",
      "Epoch 90, Training loss: 2.278473\n",
      "Test accuracy : 0.1905\n",
      "\n",
      "Epoch 91, Training loss: 2.278032\n",
      "Test accuracy : 0.1902\n",
      "\n",
      "Epoch 92, Training loss: 2.277584\n",
      "Test accuracy : 0.19\n",
      "\n",
      "Epoch 93, Training loss: 2.277130\n",
      "Test accuracy : 0.1897\n",
      "\n",
      "Epoch 94, Training loss: 2.276669\n",
      "Test accuracy : 0.1894\n",
      "\n",
      "Epoch 95, Training loss: 2.276201\n",
      "Test accuracy : 0.1892\n",
      "\n",
      "Epoch 96, Training loss: 2.275726\n",
      "Test accuracy : 0.1887\n",
      "\n",
      "Epoch 97, Training loss: 2.275244\n",
      "Test accuracy : 0.1885\n",
      "\n",
      "Epoch 98, Training loss: 2.274755\n",
      "Test accuracy : 0.1882\n",
      "\n",
      "Epoch 99, Training loss: 2.274259\n",
      "Test accuracy : 0.1879\n",
      "\n",
      "Epoch 100, Training loss: 2.273755\n",
      "Test accuracy : 0.1876\n",
      "\n",
      "Epoch 101, Training loss: 2.273244\n",
      "Test accuracy : 0.1873\n",
      "\n",
      "Epoch 102, Training loss: 2.272725\n",
      "Test accuracy : 0.1873\n",
      "\n",
      "Epoch 103, Training loss: 2.272199\n",
      "Test accuracy : 0.187\n",
      "\n",
      "Epoch 104, Training loss: 2.271665\n",
      "Test accuracy : 0.1869\n",
      "\n",
      "Epoch 105, Training loss: 2.271123\n",
      "Test accuracy : 0.1866\n",
      "\n",
      "Epoch 106, Training loss: 2.270573\n",
      "Test accuracy : 0.1864\n",
      "\n",
      "Epoch 107, Training loss: 2.270015\n",
      "Test accuracy : 0.1865\n",
      "\n",
      "Epoch 108, Training loss: 2.269449\n",
      "Test accuracy : 0.186\n",
      "\n",
      "Epoch 109, Training loss: 2.268875\n",
      "Test accuracy : 0.1861\n",
      "\n",
      "Epoch 110, Training loss: 2.268292\n",
      "Test accuracy : 0.1858\n",
      "\n",
      "Epoch 111, Training loss: 2.267701\n",
      "Test accuracy : 0.1856\n",
      "\n",
      "Epoch 112, Training loss: 2.267102\n",
      "Test accuracy : 0.1855\n",
      "\n",
      "Epoch 113, Training loss: 2.266494\n",
      "Test accuracy : 0.1853\n",
      "\n",
      "Epoch 114, Training loss: 2.265877\n",
      "Test accuracy : 0.1852\n",
      "\n",
      "Epoch 115, Training loss: 2.265251\n",
      "Test accuracy : 0.185\n",
      "\n",
      "Epoch 116, Training loss: 2.264616\n",
      "Test accuracy : 0.1848\n",
      "\n",
      "Epoch 117, Training loss: 2.263972\n",
      "Test accuracy : 0.1845\n",
      "\n",
      "Epoch 118, Training loss: 2.263319\n",
      "Test accuracy : 0.1844\n",
      "\n",
      "Epoch 119, Training loss: 2.262657\n",
      "Test accuracy : 0.1844\n",
      "\n",
      "Epoch 120, Training loss: 2.261985\n",
      "Test accuracy : 0.1844\n",
      "\n",
      "Epoch 121, Training loss: 2.261304\n",
      "Test accuracy : 0.1843\n",
      "\n",
      "Epoch 122, Training loss: 2.260613\n",
      "Test accuracy : 0.1842\n",
      "\n",
      "Epoch 123, Training loss: 2.259913\n",
      "Test accuracy : 0.1841\n",
      "\n",
      "Epoch 124, Training loss: 2.259203\n",
      "Test accuracy : 0.1842\n",
      "\n",
      "Epoch 125, Training loss: 2.258483\n",
      "Test accuracy : 0.1841\n",
      "\n",
      "Epoch 126, Training loss: 2.257753\n",
      "Test accuracy : 0.1839\n",
      "\n",
      "Epoch 127, Training loss: 2.257013\n",
      "Test accuracy : 0.1835\n",
      "\n",
      "Epoch 128, Training loss: 2.256263\n",
      "Test accuracy : 0.1835\n",
      "\n",
      "Epoch 129, Training loss: 2.255503\n",
      "Test accuracy : 0.1834\n",
      "\n",
      "Epoch 130, Training loss: 2.254733\n",
      "Test accuracy : 0.1835\n",
      "\n",
      "Epoch 131, Training loss: 2.253952\n",
      "Test accuracy : 0.1832\n",
      "\n",
      "Epoch 132, Training loss: 2.253160\n",
      "Test accuracy : 0.1829\n",
      "\n",
      "Epoch 133, Training loss: 2.252358\n",
      "Test accuracy : 0.1829\n",
      "\n",
      "Epoch 134, Training loss: 2.251546\n",
      "Test accuracy : 0.1829\n",
      "\n",
      "Epoch 135, Training loss: 2.250722\n",
      "Test accuracy : 0.1829\n",
      "\n",
      "Epoch 136, Training loss: 2.249888\n",
      "Test accuracy : 0.1828\n",
      "\n",
      "Epoch 137, Training loss: 2.249043\n",
      "Test accuracy : 0.1827\n",
      "\n",
      "Epoch 138, Training loss: 2.248186\n",
      "Test accuracy : 0.1825\n",
      "\n",
      "Epoch 139, Training loss: 2.247319\n",
      "Test accuracy : 0.1825\n",
      "\n",
      "Epoch 140, Training loss: 2.246440\n",
      "Test accuracy : 0.1824\n",
      "\n",
      "Epoch 141, Training loss: 2.245550\n",
      "Test accuracy : 0.1825\n",
      "\n",
      "Epoch 142, Training loss: 2.244649\n",
      "Test accuracy : 0.1825\n",
      "\n",
      "Epoch 143, Training loss: 2.243736\n",
      "Test accuracy : 0.1823\n",
      "\n",
      "Epoch 144, Training loss: 2.242812\n",
      "Test accuracy : 0.1822\n",
      "\n",
      "Epoch 145, Training loss: 2.241876\n",
      "Test accuracy : 0.1819\n",
      "\n",
      "Epoch 146, Training loss: 2.240928\n",
      "Test accuracy : 0.1819\n",
      "\n",
      "Epoch 147, Training loss: 2.239969\n",
      "Test accuracy : 0.1819\n",
      "\n",
      "Epoch 148, Training loss: 2.238998\n",
      "Test accuracy : 0.182\n",
      "\n",
      "Epoch 149, Training loss: 2.238015\n",
      "Test accuracy : 0.182\n",
      "\n",
      "Epoch 150, Training loss: 2.237019\n",
      "Test accuracy : 0.1822\n",
      "\n",
      "Epoch 151, Training loss: 2.236012\n",
      "Test accuracy : 0.1822\n",
      "\n",
      "Epoch 152, Training loss: 2.234993\n",
      "Test accuracy : 0.1823\n",
      "\n",
      "Epoch 153, Training loss: 2.233961\n",
      "Test accuracy : 0.1825\n",
      "\n",
      "Epoch 154, Training loss: 2.232918\n",
      "Test accuracy : 0.1825\n",
      "\n",
      "Epoch 155, Training loss: 2.231861\n",
      "Test accuracy : 0.1825\n",
      "\n",
      "Epoch 156, Training loss: 2.230793\n",
      "Test accuracy : 0.1824\n",
      "\n",
      "Epoch 157, Training loss: 2.229711\n",
      "Test accuracy : 0.1825\n",
      "\n",
      "Epoch 158, Training loss: 2.228618\n",
      "Test accuracy : 0.1826\n",
      "\n",
      "Epoch 159, Training loss: 2.227511\n",
      "Test accuracy : 0.1827\n",
      "\n",
      "Epoch 160, Training loss: 2.226392\n",
      "Test accuracy : 0.1828\n",
      "\n",
      "Epoch 161, Training loss: 2.225260\n",
      "Test accuracy : 0.183\n",
      "\n",
      "Epoch 162, Training loss: 2.224116\n",
      "Test accuracy : 0.1833\n",
      "\n",
      "Epoch 163, Training loss: 2.222958\n",
      "Test accuracy : 0.1833\n",
      "\n",
      "Epoch 164, Training loss: 2.221788\n",
      "Test accuracy : 0.1833\n",
      "\n",
      "Epoch 165, Training loss: 2.220604\n",
      "Test accuracy : 0.1833\n",
      "\n",
      "Epoch 166, Training loss: 2.219408\n",
      "Test accuracy : 0.1835\n",
      "\n",
      "Epoch 167, Training loss: 2.218198\n",
      "Test accuracy : 0.1836\n",
      "\n",
      "Epoch 168, Training loss: 2.216975\n",
      "Test accuracy : 0.1837\n",
      "\n",
      "Epoch 169, Training loss: 2.215739\n",
      "Test accuracy : 0.1839\n",
      "\n",
      "Epoch 170, Training loss: 2.214490\n",
      "Test accuracy : 0.184\n",
      "\n",
      "Epoch 171, Training loss: 2.213228\n",
      "Test accuracy : 0.1841\n",
      "\n",
      "Epoch 172, Training loss: 2.211952\n",
      "Test accuracy : 0.1844\n",
      "\n",
      "Epoch 173, Training loss: 2.210663\n",
      "Test accuracy : 0.1844\n",
      "\n",
      "Epoch 174, Training loss: 2.209360\n",
      "Test accuracy : 0.1849\n",
      "\n",
      "Epoch 175, Training loss: 2.208044\n",
      "Test accuracy : 0.1849\n",
      "\n",
      "Epoch 176, Training loss: 2.206714\n",
      "Test accuracy : 0.185\n",
      "\n",
      "Epoch 177, Training loss: 2.205371\n",
      "Test accuracy : 0.1854\n",
      "\n",
      "Epoch 178, Training loss: 2.204014\n",
      "Test accuracy : 0.1854\n",
      "\n",
      "Epoch 179, Training loss: 2.202643\n",
      "Test accuracy : 0.1859\n",
      "\n",
      "Epoch 180, Training loss: 2.201259\n",
      "Test accuracy : 0.1864\n",
      "\n",
      "Epoch 181, Training loss: 2.199861\n",
      "Test accuracy : 0.1866\n",
      "\n",
      "Epoch 182, Training loss: 2.198450\n",
      "Test accuracy : 0.1867\n",
      "\n",
      "Epoch 183, Training loss: 2.197024\n",
      "Test accuracy : 0.1867\n",
      "\n",
      "Epoch 184, Training loss: 2.195585\n",
      "Test accuracy : 0.1872\n",
      "\n",
      "Epoch 185, Training loss: 2.194132\n",
      "Test accuracy : 0.1876\n",
      "\n",
      "Epoch 186, Training loss: 2.192665\n",
      "Test accuracy : 0.1879\n",
      "\n",
      "Epoch 187, Training loss: 2.191184\n",
      "Test accuracy : 0.1883\n",
      "\n",
      "Epoch 188, Training loss: 2.189689\n",
      "Test accuracy : 0.1887\n",
      "\n",
      "Epoch 189, Training loss: 2.188180\n",
      "Test accuracy : 0.189\n",
      "\n",
      "Epoch 190, Training loss: 2.186657\n",
      "Test accuracy : 0.1891\n",
      "\n",
      "Epoch 191, Training loss: 2.185120\n",
      "Test accuracy : 0.1892\n",
      "\n",
      "Epoch 192, Training loss: 2.183569\n",
      "Test accuracy : 0.1892\n",
      "\n",
      "Epoch 193, Training loss: 2.182004\n",
      "Test accuracy : 0.1895\n",
      "\n",
      "Epoch 194, Training loss: 2.180424\n",
      "Test accuracy : 0.1899\n",
      "\n",
      "Epoch 195, Training loss: 2.178831\n",
      "Test accuracy : 0.1901\n",
      "\n",
      "Epoch 196, Training loss: 2.177223\n",
      "Test accuracy : 0.1902\n",
      "\n",
      "Epoch 197, Training loss: 2.175601\n",
      "Test accuracy : 0.1906\n",
      "\n",
      "Epoch 198, Training loss: 2.173965\n",
      "Test accuracy : 0.1909\n",
      "\n",
      "Epoch 199, Training loss: 2.172314\n",
      "Test accuracy : 0.1911\n",
      "\n",
      "Epoch 200, Training loss: 2.170649\n",
      "Test accuracy : 0.1916\n",
      "\n",
      "Epoch 201, Training loss: 2.168970\n",
      "Test accuracy : 0.1922\n",
      "\n",
      "Epoch 202, Training loss: 2.167277\n",
      "Test accuracy : 0.1927\n",
      "\n",
      "Epoch 203, Training loss: 2.165569\n",
      "Test accuracy : 0.1932\n",
      "\n",
      "Epoch 204, Training loss: 2.163846\n",
      "Test accuracy : 0.1936\n",
      "\n",
      "Epoch 205, Training loss: 2.162109\n",
      "Test accuracy : 0.1937\n",
      "\n",
      "Epoch 206, Training loss: 2.160358\n",
      "Test accuracy : 0.1942\n",
      "\n",
      "Epoch 207, Training loss: 2.158592\n",
      "Test accuracy : 0.1948\n",
      "\n",
      "Epoch 208, Training loss: 2.156811\n",
      "Test accuracy : 0.1952\n",
      "\n",
      "Epoch 209, Training loss: 2.155016\n",
      "Test accuracy : 0.1955\n",
      "\n",
      "Epoch 210, Training loss: 2.153206\n",
      "Test accuracy : 0.1961\n",
      "\n",
      "Epoch 211, Training loss: 2.151382\n",
      "Test accuracy : 0.1966\n",
      "\n",
      "Epoch 212, Training loss: 2.149542\n",
      "Test accuracy : 0.1968\n",
      "\n",
      "Epoch 213, Training loss: 2.147688\n",
      "Test accuracy : 0.197\n",
      "\n",
      "Epoch 214, Training loss: 2.145820\n",
      "Test accuracy : 0.1976\n",
      "\n",
      "Epoch 215, Training loss: 2.143936\n",
      "Test accuracy : 0.1976\n",
      "\n",
      "Epoch 216, Training loss: 2.142038\n",
      "Test accuracy : 0.1982\n",
      "\n",
      "Epoch 217, Training loss: 2.140125\n",
      "Test accuracy : 0.1988\n",
      "\n",
      "Epoch 218, Training loss: 2.138197\n",
      "Test accuracy : 0.1991\n",
      "\n",
      "Epoch 219, Training loss: 2.136254\n",
      "Test accuracy : 0.1997\n",
      "\n",
      "Epoch 220, Training loss: 2.134297\n",
      "Test accuracy : 0.2001\n",
      "\n",
      "Epoch 221, Training loss: 2.132324\n",
      "Test accuracy : 0.2007\n",
      "\n",
      "Epoch 222, Training loss: 2.130337\n",
      "Test accuracy : 0.2009\n",
      "\n",
      "Epoch 223, Training loss: 2.128334\n",
      "Test accuracy : 0.2014\n",
      "\n",
      "Epoch 224, Training loss: 2.126317\n",
      "Test accuracy : 0.2023\n",
      "\n",
      "Epoch 225, Training loss: 2.124285\n",
      "Test accuracy : 0.2027\n",
      "\n",
      "Epoch 226, Training loss: 2.122237\n",
      "Test accuracy : 0.2038\n",
      "\n",
      "Epoch 227, Training loss: 2.120175\n",
      "Test accuracy : 0.2039\n",
      "\n",
      "Epoch 228, Training loss: 2.118098\n",
      "Test accuracy : 0.2049\n",
      "\n",
      "Epoch 229, Training loss: 2.116005\n",
      "Test accuracy : 0.2057\n",
      "\n",
      "Epoch 230, Training loss: 2.113898\n",
      "Test accuracy : 0.2066\n",
      "\n",
      "Epoch 231, Training loss: 2.111775\n",
      "Test accuracy : 0.2074\n",
      "\n",
      "Epoch 232, Training loss: 2.109638\n",
      "Test accuracy : 0.2076\n",
      "\n",
      "Epoch 233, Training loss: 2.107485\n",
      "Test accuracy : 0.2088\n",
      "\n",
      "Epoch 234, Training loss: 2.105318\n",
      "Test accuracy : 0.2096\n",
      "\n",
      "Epoch 235, Training loss: 2.103135\n",
      "Test accuracy : 0.2103\n",
      "\n",
      "Epoch 236, Training loss: 2.100937\n",
      "Test accuracy : 0.2112\n",
      "\n",
      "Epoch 237, Training loss: 2.098724\n",
      "Test accuracy : 0.2134\n",
      "\n",
      "Epoch 238, Training loss: 2.096496\n",
      "Test accuracy : 0.2153\n",
      "\n",
      "Epoch 239, Training loss: 2.094253\n",
      "Test accuracy : 0.2166\n",
      "\n",
      "Epoch 240, Training loss: 2.091995\n",
      "Test accuracy : 0.2186\n",
      "\n",
      "Epoch 241, Training loss: 2.089722\n",
      "Test accuracy : 0.2194\n",
      "\n",
      "Epoch 242, Training loss: 2.087433\n",
      "Test accuracy : 0.2207\n",
      "\n",
      "Epoch 243, Training loss: 2.085130\n",
      "Test accuracy : 0.2216\n",
      "\n",
      "Epoch 244, Training loss: 2.082812\n",
      "Test accuracy : 0.2248\n",
      "\n",
      "Epoch 245, Training loss: 2.080479\n",
      "Test accuracy : 0.2269\n",
      "\n",
      "Epoch 246, Training loss: 2.078130\n",
      "Test accuracy : 0.2287\n",
      "\n",
      "Epoch 247, Training loss: 2.075767\n",
      "Test accuracy : 0.2309\n",
      "\n",
      "Epoch 248, Training loss: 2.073389\n",
      "Test accuracy : 0.2331\n",
      "\n",
      "Epoch 249, Training loss: 2.070996\n",
      "Test accuracy : 0.2357\n",
      "\n",
      "Epoch 250, Training loss: 2.068588\n",
      "Test accuracy : 0.2382\n",
      "\n",
      "Epoch 251, Training loss: 2.066165\n",
      "Test accuracy : 0.2415\n",
      "\n",
      "Epoch 252, Training loss: 2.063728\n",
      "Test accuracy : 0.2448\n",
      "\n",
      "Epoch 253, Training loss: 2.061276\n",
      "Test accuracy : 0.2482\n",
      "\n",
      "Epoch 254, Training loss: 2.058809\n",
      "Test accuracy : 0.2522\n",
      "\n",
      "Epoch 255, Training loss: 2.056328\n",
      "Test accuracy : 0.2552\n",
      "\n",
      "Epoch 256, Training loss: 2.053832\n",
      "Test accuracy : 0.2582\n",
      "\n",
      "Epoch 257, Training loss: 2.051321\n",
      "Test accuracy : 0.2616\n",
      "\n",
      "Epoch 258, Training loss: 2.048797\n",
      "Test accuracy : 0.2656\n",
      "\n",
      "Epoch 259, Training loss: 2.046258\n",
      "Test accuracy : 0.2691\n",
      "\n",
      "Epoch 260, Training loss: 2.043704\n",
      "Test accuracy : 0.2731\n",
      "\n",
      "Epoch 261, Training loss: 2.041137\n",
      "Test accuracy : 0.2767\n",
      "\n",
      "Epoch 262, Training loss: 2.038556\n",
      "Test accuracy : 0.2809\n",
      "\n",
      "Epoch 263, Training loss: 2.035961\n",
      "Test accuracy : 0.2855\n",
      "\n",
      "Epoch 264, Training loss: 2.033351\n",
      "Test accuracy : 0.2894\n",
      "\n",
      "Epoch 265, Training loss: 2.030729\n",
      "Test accuracy : 0.2933\n",
      "\n",
      "Epoch 266, Training loss: 2.028092\n",
      "Test accuracy : 0.2972\n",
      "\n",
      "Epoch 267, Training loss: 2.025443\n",
      "Test accuracy : 0.3016\n",
      "\n",
      "Epoch 268, Training loss: 2.022780\n",
      "Test accuracy : 0.3055\n",
      "\n",
      "Epoch 269, Training loss: 2.020103\n",
      "Test accuracy : 0.309\n",
      "\n",
      "Epoch 270, Training loss: 2.017414\n",
      "Test accuracy : 0.3137\n",
      "\n",
      "Epoch 271, Training loss: 2.014711\n",
      "Test accuracy : 0.3161\n",
      "\n",
      "Epoch 272, Training loss: 2.011996\n",
      "Test accuracy : 0.32\n",
      "\n",
      "Epoch 273, Training loss: 2.009269\n",
      "Test accuracy : 0.3239\n",
      "\n",
      "Epoch 274, Training loss: 2.006529\n",
      "Test accuracy : 0.3282\n",
      "\n",
      "Epoch 275, Training loss: 2.003776\n",
      "Test accuracy : 0.3331\n",
      "\n",
      "Epoch 276, Training loss: 2.001012\n",
      "Test accuracy : 0.3382\n",
      "\n",
      "Epoch 277, Training loss: 1.998236\n",
      "Test accuracy : 0.342\n",
      "\n",
      "Epoch 278, Training loss: 1.995448\n",
      "Test accuracy : 0.3462\n",
      "\n",
      "Epoch 279, Training loss: 1.992649\n",
      "Test accuracy : 0.3506\n",
      "\n",
      "Epoch 280, Training loss: 1.989839\n",
      "Test accuracy : 0.3549\n",
      "\n",
      "Epoch 281, Training loss: 1.987017\n",
      "Test accuracy : 0.3573\n",
      "\n",
      "Epoch 282, Training loss: 1.984185\n",
      "Test accuracy : 0.3612\n",
      "\n",
      "Epoch 283, Training loss: 1.981342\n",
      "Test accuracy : 0.3643\n",
      "\n",
      "Epoch 284, Training loss: 1.978489\n",
      "Test accuracy : 0.3682\n",
      "\n",
      "Epoch 285, Training loss: 1.975626\n",
      "Test accuracy : 0.3719\n",
      "\n",
      "Epoch 286, Training loss: 1.972753\n",
      "Test accuracy : 0.3744\n",
      "\n",
      "Epoch 287, Training loss: 1.969870\n",
      "Test accuracy : 0.3773\n",
      "\n",
      "Epoch 288, Training loss: 1.966978\n",
      "Test accuracy : 0.3798\n",
      "\n",
      "Epoch 289, Training loss: 1.964077\n",
      "Test accuracy : 0.3833\n",
      "\n",
      "Epoch 290, Training loss: 1.961167\n",
      "Test accuracy : 0.3857\n",
      "\n",
      "Epoch 291, Training loss: 1.958249\n",
      "Test accuracy : 0.3883\n",
      "\n",
      "Epoch 292, Training loss: 1.955323\n",
      "Test accuracy : 0.3907\n",
      "\n",
      "Epoch 293, Training loss: 1.952388\n",
      "Test accuracy : 0.3928\n",
      "\n",
      "Epoch 294, Training loss: 1.949446\n",
      "Test accuracy : 0.3948\n",
      "\n",
      "Epoch 295, Training loss: 1.946497\n",
      "Test accuracy : 0.3976\n",
      "\n",
      "Epoch 296, Training loss: 1.943540\n",
      "Test accuracy : 0.399\n",
      "\n",
      "Epoch 297, Training loss: 1.940577\n",
      "Test accuracy : 0.4016\n",
      "\n",
      "Epoch 298, Training loss: 1.937607\n",
      "Test accuracy : 0.4043\n",
      "\n",
      "Epoch 299, Training loss: 1.934630\n",
      "Test accuracy : 0.4056\n",
      "\n",
      "Epoch 300, Training loss: 1.931648\n",
      "Test accuracy : 0.4069\n",
      "\n",
      "Epoch 301, Training loss: 1.928660\n",
      "Test accuracy : 0.4091\n",
      "\n",
      "Epoch 302, Training loss: 1.925667\n",
      "Test accuracy : 0.4113\n",
      "\n",
      "Epoch 303, Training loss: 1.922668\n",
      "Test accuracy : 0.4127\n",
      "\n",
      "Epoch 304, Training loss: 1.919665\n",
      "Test accuracy : 0.414\n",
      "\n",
      "Epoch 305, Training loss: 1.916657\n",
      "Test accuracy : 0.4157\n",
      "\n",
      "Epoch 306, Training loss: 1.913645\n",
      "Test accuracy : 0.4175\n",
      "\n",
      "Epoch 307, Training loss: 1.910629\n",
      "Test accuracy : 0.4197\n",
      "\n",
      "Epoch 308, Training loss: 1.907610\n",
      "Test accuracy : 0.4211\n",
      "\n",
      "Epoch 309, Training loss: 1.904587\n",
      "Test accuracy : 0.4231\n",
      "\n",
      "Epoch 310, Training loss: 1.901561\n",
      "Test accuracy : 0.4246\n",
      "\n",
      "Epoch 311, Training loss: 1.898533\n",
      "Test accuracy : 0.4262\n",
      "\n",
      "Epoch 312, Training loss: 1.895502\n",
      "Test accuracy : 0.4285\n",
      "\n",
      "Epoch 313, Training loss: 1.892469\n",
      "Test accuracy : 0.4295\n",
      "\n",
      "Epoch 314, Training loss: 1.889434\n",
      "Test accuracy : 0.4303\n",
      "\n",
      "Epoch 315, Training loss: 1.886398\n",
      "Test accuracy : 0.4319\n",
      "\n",
      "Epoch 316, Training loss: 1.883360\n",
      "Test accuracy : 0.4334\n",
      "\n",
      "Epoch 317, Training loss: 1.880322\n",
      "Test accuracy : 0.4342\n",
      "\n",
      "Epoch 318, Training loss: 1.877282\n",
      "Test accuracy : 0.4351\n",
      "\n",
      "Epoch 319, Training loss: 1.874243\n",
      "Test accuracy : 0.4364\n",
      "\n",
      "Epoch 320, Training loss: 1.871203\n",
      "Test accuracy : 0.4375\n",
      "\n",
      "Epoch 321, Training loss: 1.868163\n",
      "Test accuracy : 0.4384\n",
      "\n",
      "Epoch 322, Training loss: 1.865124\n",
      "Test accuracy : 0.4392\n",
      "\n",
      "Epoch 323, Training loss: 1.862086\n",
      "Test accuracy : 0.4406\n",
      "\n",
      "Epoch 324, Training loss: 1.859048\n",
      "Test accuracy : 0.4416\n",
      "\n",
      "Epoch 325, Training loss: 1.856012\n",
      "Test accuracy : 0.4429\n",
      "\n",
      "Epoch 326, Training loss: 1.852977\n",
      "Test accuracy : 0.4434\n",
      "\n",
      "Epoch 327, Training loss: 1.849943\n",
      "Test accuracy : 0.4435\n",
      "\n",
      "Epoch 328, Training loss: 1.846911\n",
      "Test accuracy : 0.4441\n",
      "\n",
      "Epoch 329, Training loss: 1.843882\n",
      "Test accuracy : 0.4447\n",
      "\n",
      "Epoch 330, Training loss: 1.840855\n",
      "Test accuracy : 0.4455\n",
      "\n",
      "Epoch 331, Training loss: 1.837830\n",
      "Test accuracy : 0.4462\n",
      "\n",
      "Epoch 332, Training loss: 1.834808\n",
      "Test accuracy : 0.4462\n",
      "\n",
      "Epoch 333, Training loss: 1.831789\n",
      "Test accuracy : 0.4465\n",
      "\n",
      "Epoch 334, Training loss: 1.828773\n",
      "Test accuracy : 0.4464\n",
      "\n",
      "Epoch 335, Training loss: 1.825761\n",
      "Test accuracy : 0.4466\n",
      "\n",
      "Epoch 336, Training loss: 1.822752\n",
      "Test accuracy : 0.4466\n",
      "\n",
      "Epoch 337, Training loss: 1.819747\n",
      "Test accuracy : 0.4461\n",
      "\n",
      "Epoch 338, Training loss: 1.816746\n",
      "Test accuracy : 0.446\n",
      "\n",
      "Epoch 339, Training loss: 1.813750\n",
      "Test accuracy : 0.4466\n",
      "\n",
      "Epoch 340, Training loss: 1.810757\n",
      "Test accuracy : 0.4466\n",
      "\n",
      "Epoch 341, Training loss: 1.807769\n",
      "Test accuracy : 0.4465\n",
      "\n",
      "Epoch 342, Training loss: 1.804786\n",
      "Test accuracy : 0.4456\n",
      "\n",
      "Epoch 343, Training loss: 1.801807\n",
      "Test accuracy : 0.4461\n",
      "\n",
      "Epoch 344, Training loss: 1.798834\n",
      "Test accuracy : 0.446\n",
      "\n",
      "Epoch 345, Training loss: 1.795865\n",
      "Test accuracy : 0.4452\n",
      "\n",
      "Epoch 346, Training loss: 1.792902\n",
      "Test accuracy : 0.4452\n",
      "\n",
      "Epoch 347, Training loss: 1.789944\n",
      "Test accuracy : 0.4452\n",
      "\n",
      "Epoch 348, Training loss: 1.786992\n",
      "Test accuracy : 0.4458\n",
      "\n",
      "Epoch 349, Training loss: 1.784046\n",
      "Test accuracy : 0.4451\n",
      "\n",
      "Epoch 350, Training loss: 1.781105\n",
      "Test accuracy : 0.4448\n",
      "\n",
      "Epoch 351, Training loss: 1.778171\n",
      "Test accuracy : 0.4444\n",
      "\n",
      "Epoch 352, Training loss: 1.775242\n",
      "Test accuracy : 0.4446\n",
      "\n",
      "Epoch 353, Training loss: 1.772319\n",
      "Test accuracy : 0.4446\n",
      "\n",
      "Epoch 354, Training loss: 1.769403\n",
      "Test accuracy : 0.4454\n",
      "\n",
      "Epoch 355, Training loss: 1.766494\n",
      "Test accuracy : 0.4454\n",
      "\n",
      "Epoch 356, Training loss: 1.763590\n",
      "Test accuracy : 0.4451\n",
      "\n",
      "Epoch 357, Training loss: 1.760694\n",
      "Test accuracy : 0.445\n",
      "\n",
      "Epoch 358, Training loss: 1.757804\n",
      "Test accuracy : 0.4451\n",
      "\n",
      "Epoch 359, Training loss: 1.754921\n",
      "Test accuracy : 0.4452\n",
      "\n",
      "Epoch 360, Training loss: 1.752044\n",
      "Test accuracy : 0.4449\n",
      "\n",
      "Epoch 361, Training loss: 1.749175\n",
      "Test accuracy : 0.445\n",
      "\n",
      "Epoch 362, Training loss: 1.746313\n",
      "Test accuracy : 0.4454\n",
      "\n",
      "Epoch 363, Training loss: 1.743458\n",
      "Test accuracy : 0.4461\n",
      "\n",
      "Epoch 364, Training loss: 1.740610\n",
      "Test accuracy : 0.4461\n",
      "\n",
      "Epoch 365, Training loss: 1.737769\n",
      "Test accuracy : 0.4454\n",
      "\n",
      "Epoch 366, Training loss: 1.734936\n",
      "Test accuracy : 0.4451\n",
      "\n",
      "Epoch 367, Training loss: 1.732110\n",
      "Test accuracy : 0.4451\n",
      "\n",
      "Epoch 368, Training loss: 1.729292\n",
      "Test accuracy : 0.4449\n",
      "\n",
      "Epoch 369, Training loss: 1.726481\n",
      "Test accuracy : 0.445\n",
      "\n",
      "Epoch 370, Training loss: 1.723678\n",
      "Test accuracy : 0.4456\n",
      "\n",
      "Epoch 371, Training loss: 1.720882\n",
      "Test accuracy : 0.4456\n",
      "\n",
      "Epoch 372, Training loss: 1.718094\n",
      "Test accuracy : 0.4455\n",
      "\n",
      "Epoch 373, Training loss: 1.715314\n",
      "Test accuracy : 0.4457\n",
      "\n",
      "Epoch 374, Training loss: 1.712541\n",
      "Test accuracy : 0.4464\n",
      "\n",
      "Epoch 375, Training loss: 1.709777\n",
      "Test accuracy : 0.4464\n",
      "\n",
      "Epoch 376, Training loss: 1.707020\n",
      "Test accuracy : 0.4468\n",
      "\n",
      "Epoch 377, Training loss: 1.704271\n",
      "Test accuracy : 0.4467\n",
      "\n",
      "Epoch 378, Training loss: 1.701530\n",
      "Test accuracy : 0.4469\n",
      "\n",
      "Epoch 379, Training loss: 1.698797\n",
      "Test accuracy : 0.4472\n",
      "\n",
      "Epoch 380, Training loss: 1.696072\n",
      "Test accuracy : 0.4469\n",
      "\n",
      "Epoch 381, Training loss: 1.693355\n",
      "Test accuracy : 0.4472\n",
      "\n",
      "Epoch 382, Training loss: 1.690646\n",
      "Test accuracy : 0.4471\n",
      "\n",
      "Epoch 383, Training loss: 1.687945\n",
      "Test accuracy : 0.4476\n",
      "\n",
      "Epoch 384, Training loss: 1.685252\n",
      "Test accuracy : 0.4477\n",
      "\n",
      "Epoch 385, Training loss: 1.682567\n",
      "Test accuracy : 0.4482\n",
      "\n",
      "Epoch 386, Training loss: 1.679891\n",
      "Test accuracy : 0.4487\n",
      "\n",
      "Epoch 387, Training loss: 1.677222\n",
      "Test accuracy : 0.4496\n",
      "\n",
      "Epoch 388, Training loss: 1.674562\n",
      "Test accuracy : 0.4496\n",
      "\n",
      "Epoch 389, Training loss: 1.671910\n",
      "Test accuracy : 0.4505\n",
      "\n",
      "Epoch 390, Training loss: 1.669266\n",
      "Test accuracy : 0.4512\n",
      "\n",
      "Epoch 391, Training loss: 1.666631\n",
      "Test accuracy : 0.4517\n",
      "\n",
      "Epoch 392, Training loss: 1.664004\n",
      "Test accuracy : 0.4527\n",
      "\n",
      "Epoch 393, Training loss: 1.661385\n",
      "Test accuracy : 0.4528\n",
      "\n",
      "Epoch 394, Training loss: 1.658774\n",
      "Test accuracy : 0.4536\n",
      "\n",
      "Epoch 395, Training loss: 1.656172\n",
      "Test accuracy : 0.4543\n",
      "\n",
      "Epoch 396, Training loss: 1.653578\n",
      "Test accuracy : 0.4555\n",
      "\n",
      "Epoch 397, Training loss: 1.650992\n",
      "Test accuracy : 0.4557\n",
      "\n",
      "Epoch 398, Training loss: 1.648415\n",
      "Test accuracy : 0.4559\n",
      "\n",
      "Epoch 399, Training loss: 1.645846\n",
      "Test accuracy : 0.4566\n",
      "\n",
      "Epoch 400, Training loss: 1.643285\n",
      "Test accuracy : 0.457\n",
      "\n",
      "Epoch 401, Training loss: 1.640733\n",
      "Test accuracy : 0.4577\n",
      "\n",
      "Epoch 402, Training loss: 1.638189\n",
      "Test accuracy : 0.4576\n",
      "\n",
      "Epoch 403, Training loss: 1.635653\n",
      "Test accuracy : 0.4579\n",
      "\n",
      "Epoch 404, Training loss: 1.633126\n",
      "Test accuracy : 0.4583\n",
      "\n",
      "Epoch 405, Training loss: 1.630607\n",
      "Test accuracy : 0.4589\n",
      "\n",
      "Epoch 406, Training loss: 1.628097\n",
      "Test accuracy : 0.4592\n",
      "\n",
      "Epoch 407, Training loss: 1.625595\n",
      "Test accuracy : 0.4603\n",
      "\n",
      "Epoch 408, Training loss: 1.623101\n",
      "Test accuracy : 0.4607\n",
      "\n",
      "Epoch 409, Training loss: 1.620616\n",
      "Test accuracy : 0.4614\n",
      "\n",
      "Epoch 410, Training loss: 1.618139\n",
      "Test accuracy : 0.4618\n",
      "\n",
      "Epoch 411, Training loss: 1.615671\n",
      "Test accuracy : 0.4629\n",
      "\n",
      "Epoch 412, Training loss: 1.613211\n",
      "Test accuracy : 0.4631\n",
      "\n",
      "Epoch 413, Training loss: 1.610759\n",
      "Test accuracy : 0.4636\n",
      "\n",
      "Epoch 414, Training loss: 1.608316\n",
      "Test accuracy : 0.4641\n",
      "\n",
      "Epoch 415, Training loss: 1.605881\n",
      "Test accuracy : 0.4648\n",
      "\n",
      "Epoch 416, Training loss: 1.603454\n",
      "Test accuracy : 0.4649\n",
      "\n",
      "Epoch 417, Training loss: 1.601036\n",
      "Test accuracy : 0.4653\n",
      "\n",
      "Epoch 418, Training loss: 1.598626\n",
      "Test accuracy : 0.4658\n",
      "\n",
      "Epoch 419, Training loss: 1.596225\n",
      "Test accuracy : 0.4666\n",
      "\n",
      "Epoch 420, Training loss: 1.593831\n",
      "Test accuracy : 0.4672\n",
      "\n",
      "Epoch 421, Training loss: 1.591446\n",
      "Test accuracy : 0.4678\n",
      "\n",
      "Epoch 422, Training loss: 1.589069\n",
      "Test accuracy : 0.4684\n",
      "\n",
      "Epoch 423, Training loss: 1.586701\n",
      "Test accuracy : 0.4689\n",
      "\n",
      "Epoch 424, Training loss: 1.584341\n",
      "Test accuracy : 0.469\n",
      "\n",
      "Epoch 425, Training loss: 1.581989\n",
      "Test accuracy : 0.47\n",
      "\n",
      "Epoch 426, Training loss: 1.579645\n",
      "Test accuracy : 0.4708\n",
      "\n",
      "Epoch 427, Training loss: 1.577310\n",
      "Test accuracy : 0.4713\n",
      "\n",
      "Epoch 428, Training loss: 1.574982\n",
      "Test accuracy : 0.472\n",
      "\n",
      "Epoch 429, Training loss: 1.572663\n",
      "Test accuracy : 0.4737\n",
      "\n",
      "Epoch 430, Training loss: 1.570352\n",
      "Test accuracy : 0.4746\n",
      "\n",
      "Epoch 431, Training loss: 1.568049\n",
      "Test accuracy : 0.4747\n",
      "\n",
      "Epoch 432, Training loss: 1.565754\n",
      "Test accuracy : 0.4758\n",
      "\n",
      "Epoch 433, Training loss: 1.563468\n",
      "Test accuracy : 0.4771\n",
      "\n",
      "Epoch 434, Training loss: 1.561189\n",
      "Test accuracy : 0.4792\n",
      "\n",
      "Epoch 435, Training loss: 1.558919\n",
      "Test accuracy : 0.4798\n",
      "\n",
      "Epoch 436, Training loss: 1.556656\n",
      "Test accuracy : 0.4809\n",
      "\n",
      "Epoch 437, Training loss: 1.554401\n",
      "Test accuracy : 0.482\n",
      "\n",
      "Epoch 438, Training loss: 1.552155\n",
      "Test accuracy : 0.483\n",
      "\n",
      "Epoch 439, Training loss: 1.549916\n",
      "Test accuracy : 0.4841\n",
      "\n",
      "Epoch 440, Training loss: 1.547686\n",
      "Test accuracy : 0.4863\n",
      "\n",
      "Epoch 441, Training loss: 1.545463\n",
      "Test accuracy : 0.4881\n",
      "\n",
      "Epoch 442, Training loss: 1.543248\n",
      "Test accuracy : 0.4901\n",
      "\n",
      "Epoch 443, Training loss: 1.541041\n",
      "Test accuracy : 0.4922\n",
      "\n",
      "Epoch 444, Training loss: 1.538841\n",
      "Test accuracy : 0.4938\n",
      "\n",
      "Epoch 445, Training loss: 1.536650\n",
      "Test accuracy : 0.4955\n",
      "\n",
      "Epoch 446, Training loss: 1.534466\n",
      "Test accuracy : 0.4972\n",
      "\n",
      "Epoch 447, Training loss: 1.532290\n",
      "Test accuracy : 0.4991\n",
      "\n",
      "Epoch 448, Training loss: 1.530122\n",
      "Test accuracy : 0.5004\n",
      "\n",
      "Epoch 449, Training loss: 1.527961\n",
      "Test accuracy : 0.5025\n",
      "\n",
      "Epoch 450, Training loss: 1.525808\n",
      "Test accuracy : 0.5044\n",
      "\n",
      "Epoch 451, Training loss: 1.523663\n",
      "Test accuracy : 0.5062\n",
      "\n",
      "Epoch 452, Training loss: 1.521525\n",
      "Test accuracy : 0.507\n",
      "\n",
      "Epoch 453, Training loss: 1.519395\n",
      "Test accuracy : 0.5087\n",
      "\n",
      "Epoch 454, Training loss: 1.517272\n",
      "Test accuracy : 0.5106\n",
      "\n",
      "Epoch 455, Training loss: 1.515157\n",
      "Test accuracy : 0.5123\n",
      "\n",
      "Epoch 456, Training loss: 1.513049\n",
      "Test accuracy : 0.5135\n",
      "\n",
      "Epoch 457, Training loss: 1.510949\n",
      "Test accuracy : 0.5151\n",
      "\n",
      "Epoch 458, Training loss: 1.508856\n",
      "Test accuracy : 0.5166\n",
      "\n",
      "Epoch 459, Training loss: 1.506770\n",
      "Test accuracy : 0.5181\n",
      "\n",
      "Epoch 460, Training loss: 1.504692\n",
      "Test accuracy : 0.5196\n",
      "\n",
      "Epoch 461, Training loss: 1.502620\n",
      "Test accuracy : 0.523\n",
      "\n",
      "Epoch 462, Training loss: 1.500557\n",
      "Test accuracy : 0.5245\n",
      "\n",
      "Epoch 463, Training loss: 1.498500\n",
      "Test accuracy : 0.5258\n",
      "\n",
      "Epoch 464, Training loss: 1.496451\n",
      "Test accuracy : 0.5269\n",
      "\n",
      "Epoch 465, Training loss: 1.494408\n",
      "Test accuracy : 0.5289\n",
      "\n",
      "Epoch 466, Training loss: 1.492373\n",
      "Test accuracy : 0.5307\n",
      "\n",
      "Epoch 467, Training loss: 1.490345\n",
      "Test accuracy : 0.5315\n",
      "\n",
      "Epoch 468, Training loss: 1.488324\n",
      "Test accuracy : 0.5334\n",
      "\n",
      "Epoch 469, Training loss: 1.486310\n",
      "Test accuracy : 0.5351\n",
      "\n",
      "Epoch 470, Training loss: 1.484303\n",
      "Test accuracy : 0.5367\n",
      "\n",
      "Epoch 471, Training loss: 1.482303\n",
      "Test accuracy : 0.5375\n",
      "\n",
      "Epoch 472, Training loss: 1.480310\n",
      "Test accuracy : 0.5387\n",
      "\n",
      "Epoch 473, Training loss: 1.478323\n",
      "Test accuracy : 0.5393\n",
      "\n",
      "Epoch 474, Training loss: 1.476344\n",
      "Test accuracy : 0.5413\n",
      "\n",
      "Epoch 475, Training loss: 1.474371\n",
      "Test accuracy : 0.5427\n",
      "\n",
      "Epoch 476, Training loss: 1.472405\n",
      "Test accuracy : 0.5441\n",
      "\n",
      "Epoch 477, Training loss: 1.470445\n",
      "Test accuracy : 0.5453\n",
      "\n",
      "Epoch 478, Training loss: 1.468493\n",
      "Test accuracy : 0.5463\n",
      "\n",
      "Epoch 479, Training loss: 1.466547\n",
      "Test accuracy : 0.5481\n",
      "\n",
      "Epoch 480, Training loss: 1.464607\n",
      "Test accuracy : 0.5487\n",
      "\n",
      "Epoch 481, Training loss: 1.462674\n",
      "Test accuracy : 0.5502\n",
      "\n",
      "Epoch 482, Training loss: 1.460748\n",
      "Test accuracy : 0.551\n",
      "\n",
      "Epoch 483, Training loss: 1.458828\n",
      "Test accuracy : 0.5512\n",
      "\n",
      "Epoch 484, Training loss: 1.456915\n",
      "Test accuracy : 0.5523\n",
      "\n",
      "Epoch 485, Training loss: 1.455008\n",
      "Test accuracy : 0.553\n",
      "\n",
      "Epoch 486, Training loss: 1.453107\n",
      "Test accuracy : 0.5536\n",
      "\n",
      "Epoch 487, Training loss: 1.451213\n",
      "Test accuracy : 0.5543\n",
      "\n",
      "Epoch 488, Training loss: 1.449325\n",
      "Test accuracy : 0.5555\n",
      "\n",
      "Epoch 489, Training loss: 1.447443\n",
      "Test accuracy : 0.5554\n",
      "\n",
      "Epoch 490, Training loss: 1.445568\n",
      "Test accuracy : 0.5562\n",
      "\n",
      "Epoch 491, Training loss: 1.443698\n",
      "Test accuracy : 0.5571\n",
      "\n",
      "Epoch 492, Training loss: 1.441835\n",
      "Test accuracy : 0.5585\n",
      "\n",
      "Epoch 493, Training loss: 1.439978\n",
      "Test accuracy : 0.5589\n",
      "\n",
      "Epoch 494, Training loss: 1.438127\n",
      "Test accuracy : 0.5592\n",
      "\n",
      "Epoch 495, Training loss: 1.436282\n",
      "Test accuracy : 0.5595\n",
      "\n",
      "Epoch 496, Training loss: 1.434443\n",
      "Test accuracy : 0.5602\n",
      "\n",
      "Epoch 497, Training loss: 1.432610\n",
      "Test accuracy : 0.5608\n",
      "\n",
      "Epoch 498, Training loss: 1.430783\n",
      "Test accuracy : 0.5615\n",
      "\n",
      "Epoch 499, Training loss: 1.428962\n",
      "Test accuracy : 0.5615\n",
      "\n",
      "Epoch 500, Training loss: 1.427147\n",
      "Test accuracy : 0.5622\n",
      "\n",
      "Epoch 501, Training loss: 1.425338\n",
      "Test accuracy : 0.563\n",
      "\n",
      "Epoch 502, Training loss: 1.423534\n",
      "Test accuracy : 0.5638\n",
      "\n",
      "Epoch 503, Training loss: 1.421736\n",
      "Test accuracy : 0.5643\n",
      "\n",
      "Epoch 504, Training loss: 1.419944\n",
      "Test accuracy : 0.5648\n",
      "\n",
      "Epoch 505, Training loss: 1.418158\n",
      "Test accuracy : 0.5655\n",
      "\n",
      "Epoch 506, Training loss: 1.416377\n",
      "Test accuracy : 0.5657\n",
      "\n",
      "Epoch 507, Training loss: 1.414602\n",
      "Test accuracy : 0.5664\n",
      "\n",
      "Epoch 508, Training loss: 1.412832\n",
      "Test accuracy : 0.5664\n",
      "\n",
      "Epoch 509, Training loss: 1.411068\n",
      "Test accuracy : 0.5669\n",
      "\n",
      "Epoch 510, Training loss: 1.409310\n",
      "Test accuracy : 0.567\n",
      "\n",
      "Epoch 511, Training loss: 1.407557\n",
      "Test accuracy : 0.5675\n",
      "\n",
      "Epoch 512, Training loss: 1.405809\n",
      "Test accuracy : 0.5676\n",
      "\n",
      "Epoch 513, Training loss: 1.404067\n",
      "Test accuracy : 0.5681\n",
      "\n",
      "Epoch 514, Training loss: 1.402331\n",
      "Test accuracy : 0.5685\n",
      "\n",
      "Epoch 515, Training loss: 1.400599\n",
      "Test accuracy : 0.5685\n",
      "\n",
      "Epoch 516, Training loss: 1.398873\n",
      "Test accuracy : 0.5695\n",
      "\n",
      "Epoch 517, Training loss: 1.397152\n",
      "Test accuracy : 0.5697\n",
      "\n",
      "Epoch 518, Training loss: 1.395437\n",
      "Test accuracy : 0.5703\n",
      "\n",
      "Epoch 519, Training loss: 1.393727\n",
      "Test accuracy : 0.5706\n",
      "\n",
      "Epoch 520, Training loss: 1.392021\n",
      "Test accuracy : 0.5709\n",
      "\n",
      "Epoch 521, Training loss: 1.390321\n",
      "Test accuracy : 0.5718\n",
      "\n",
      "Epoch 522, Training loss: 1.388627\n",
      "Test accuracy : 0.5722\n",
      "\n",
      "Epoch 523, Training loss: 1.386937\n",
      "Test accuracy : 0.5726\n",
      "\n",
      "Epoch 524, Training loss: 1.385252\n",
      "Test accuracy : 0.5728\n",
      "\n",
      "Epoch 525, Training loss: 1.383573\n",
      "Test accuracy : 0.5735\n",
      "\n",
      "Epoch 526, Training loss: 1.381898\n",
      "Test accuracy : 0.5737\n",
      "\n",
      "Epoch 527, Training loss: 1.380229\n",
      "Test accuracy : 0.5742\n",
      "\n",
      "Epoch 528, Training loss: 1.378564\n",
      "Test accuracy : 0.5742\n",
      "\n",
      "Epoch 529, Training loss: 1.376904\n",
      "Test accuracy : 0.5747\n",
      "\n",
      "Epoch 530, Training loss: 1.375249\n",
      "Test accuracy : 0.5749\n",
      "\n",
      "Epoch 531, Training loss: 1.373599\n",
      "Test accuracy : 0.5752\n",
      "\n",
      "Epoch 532, Training loss: 1.371954\n",
      "Test accuracy : 0.5755\n",
      "\n",
      "Epoch 533, Training loss: 1.370314\n",
      "Test accuracy : 0.5756\n",
      "\n",
      "Epoch 534, Training loss: 1.368678\n",
      "Test accuracy : 0.5759\n",
      "\n",
      "Epoch 535, Training loss: 1.367048\n",
      "Test accuracy : 0.576\n",
      "\n",
      "Epoch 536, Training loss: 1.365421\n",
      "Test accuracy : 0.5763\n",
      "\n",
      "Epoch 537, Training loss: 1.363800\n",
      "Test accuracy : 0.5763\n",
      "\n",
      "Epoch 538, Training loss: 1.362183\n",
      "Test accuracy : 0.5764\n",
      "\n",
      "Epoch 539, Training loss: 1.360571\n",
      "Test accuracy : 0.5765\n",
      "\n",
      "Epoch 540, Training loss: 1.358963\n",
      "Test accuracy : 0.577\n",
      "\n",
      "Epoch 541, Training loss: 1.357361\n",
      "Test accuracy : 0.5774\n",
      "\n",
      "Epoch 542, Training loss: 1.355762\n",
      "Test accuracy : 0.5778\n",
      "\n",
      "Epoch 543, Training loss: 1.354168\n",
      "Test accuracy : 0.578\n",
      "\n",
      "Epoch 544, Training loss: 1.352579\n",
      "Test accuracy : 0.5784\n",
      "\n",
      "Epoch 545, Training loss: 1.350994\n",
      "Test accuracy : 0.5787\n",
      "\n",
      "Epoch 546, Training loss: 1.349414\n",
      "Test accuracy : 0.5785\n",
      "\n",
      "Epoch 547, Training loss: 1.347838\n",
      "Test accuracy : 0.579\n",
      "\n",
      "Epoch 548, Training loss: 1.346266\n",
      "Test accuracy : 0.5792\n",
      "\n",
      "Epoch 549, Training loss: 1.344699\n",
      "Test accuracy : 0.5797\n",
      "\n",
      "Epoch 550, Training loss: 1.343136\n",
      "Test accuracy : 0.5797\n",
      "\n",
      "Epoch 551, Training loss: 1.341577\n",
      "Test accuracy : 0.5805\n",
      "\n",
      "Epoch 552, Training loss: 1.340023\n",
      "Test accuracy : 0.5804\n",
      "\n",
      "Epoch 553, Training loss: 1.338473\n",
      "Test accuracy : 0.5805\n",
      "\n",
      "Epoch 554, Training loss: 1.336927\n",
      "Test accuracy : 0.5808\n",
      "\n",
      "Epoch 555, Training loss: 1.335386\n",
      "Test accuracy : 0.5814\n",
      "\n",
      "Epoch 556, Training loss: 1.333848\n",
      "Test accuracy : 0.5822\n",
      "\n",
      "Epoch 557, Training loss: 1.332315\n",
      "Test accuracy : 0.5825\n",
      "\n",
      "Epoch 558, Training loss: 1.330786\n",
      "Test accuracy : 0.5822\n",
      "\n",
      "Epoch 559, Training loss: 1.329262\n",
      "Test accuracy : 0.5831\n",
      "\n",
      "Epoch 560, Training loss: 1.327741\n",
      "Test accuracy : 0.5837\n",
      "\n",
      "Epoch 561, Training loss: 1.326224\n",
      "Test accuracy : 0.5839\n",
      "\n",
      "Epoch 562, Training loss: 1.324712\n",
      "Test accuracy : 0.5838\n",
      "\n",
      "Epoch 563, Training loss: 1.323203\n",
      "Test accuracy : 0.5843\n",
      "\n",
      "Epoch 564, Training loss: 1.321699\n",
      "Test accuracy : 0.5848\n",
      "\n",
      "Epoch 565, Training loss: 1.320199\n",
      "Test accuracy : 0.5849\n",
      "\n",
      "Epoch 566, Training loss: 1.318702\n",
      "Test accuracy : 0.5847\n",
      "\n",
      "Epoch 567, Training loss: 1.317210\n",
      "Test accuracy : 0.585\n",
      "\n",
      "Epoch 568, Training loss: 1.315721\n",
      "Test accuracy : 0.5851\n",
      "\n",
      "Epoch 569, Training loss: 1.314237\n",
      "Test accuracy : 0.5851\n",
      "\n",
      "Epoch 570, Training loss: 1.312756\n",
      "Test accuracy : 0.5856\n",
      "\n",
      "Epoch 571, Training loss: 1.311280\n",
      "Test accuracy : 0.5864\n",
      "\n",
      "Epoch 572, Training loss: 1.309807\n",
      "Test accuracy : 0.5864\n",
      "\n",
      "Epoch 573, Training loss: 1.308338\n",
      "Test accuracy : 0.5868\n",
      "\n",
      "Epoch 574, Training loss: 1.306873\n",
      "Test accuracy : 0.5868\n",
      "\n",
      "Epoch 575, Training loss: 1.305411\n",
      "Test accuracy : 0.5867\n",
      "\n",
      "Epoch 576, Training loss: 1.303954\n",
      "Test accuracy : 0.5874\n",
      "\n",
      "Epoch 577, Training loss: 1.302500\n",
      "Test accuracy : 0.5879\n",
      "\n",
      "Epoch 578, Training loss: 1.301050\n",
      "Test accuracy : 0.5881\n",
      "\n",
      "Epoch 579, Training loss: 1.299604\n",
      "Test accuracy : 0.5887\n",
      "\n",
      "Epoch 580, Training loss: 1.298162\n",
      "Test accuracy : 0.5891\n",
      "\n",
      "Epoch 581, Training loss: 1.296723\n",
      "Test accuracy : 0.5892\n",
      "\n",
      "Epoch 582, Training loss: 1.295288\n",
      "Test accuracy : 0.5897\n",
      "\n",
      "Epoch 583, Training loss: 1.293857\n",
      "Test accuracy : 0.5902\n",
      "\n",
      "Epoch 584, Training loss: 1.292429\n",
      "Test accuracy : 0.5908\n",
      "\n",
      "Epoch 585, Training loss: 1.291005\n",
      "Test accuracy : 0.5912\n",
      "\n",
      "Epoch 586, Training loss: 1.289585\n",
      "Test accuracy : 0.5918\n",
      "\n",
      "Epoch 587, Training loss: 1.288169\n",
      "Test accuracy : 0.5922\n",
      "\n",
      "Epoch 588, Training loss: 1.286756\n",
      "Test accuracy : 0.5925\n",
      "\n",
      "Epoch 589, Training loss: 1.285346\n",
      "Test accuracy : 0.5927\n",
      "\n",
      "Epoch 590, Training loss: 1.283940\n",
      "Test accuracy : 0.5931\n",
      "\n",
      "Epoch 591, Training loss: 1.282538\n",
      "Test accuracy : 0.5936\n",
      "\n",
      "Epoch 592, Training loss: 1.281139\n",
      "Test accuracy : 0.5938\n",
      "\n",
      "Epoch 593, Training loss: 1.279744\n",
      "Test accuracy : 0.5937\n",
      "\n",
      "Epoch 594, Training loss: 1.278353\n",
      "Test accuracy : 0.5937\n",
      "\n",
      "Epoch 595, Training loss: 1.276965\n",
      "Test accuracy : 0.594\n",
      "\n",
      "Epoch 596, Training loss: 1.275580\n",
      "Test accuracy : 0.5939\n",
      "\n",
      "Epoch 597, Training loss: 1.274199\n",
      "Test accuracy : 0.5941\n",
      "\n",
      "Epoch 598, Training loss: 1.272822\n",
      "Test accuracy : 0.5946\n",
      "\n",
      "Epoch 599, Training loss: 1.271447\n",
      "Test accuracy : 0.5946\n",
      "\n",
      "Epoch 600, Training loss: 1.270077\n",
      "Test accuracy : 0.595\n",
      "\n",
      "Epoch 601, Training loss: 1.268710\n",
      "Test accuracy : 0.5951\n",
      "\n",
      "Epoch 602, Training loss: 1.267346\n",
      "Test accuracy : 0.5953\n",
      "\n",
      "Epoch 603, Training loss: 1.265985\n",
      "Test accuracy : 0.596\n",
      "\n",
      "Epoch 604, Training loss: 1.264629\n",
      "Test accuracy : 0.596\n",
      "\n",
      "Epoch 605, Training loss: 1.263275\n",
      "Test accuracy : 0.5964\n",
      "\n",
      "Epoch 606, Training loss: 1.261925\n",
      "Test accuracy : 0.5965\n",
      "\n",
      "Epoch 607, Training loss: 1.260578\n",
      "Test accuracy : 0.5967\n",
      "\n",
      "Epoch 608, Training loss: 1.259235\n",
      "Test accuracy : 0.5968\n",
      "\n",
      "Epoch 609, Training loss: 1.257895\n",
      "Test accuracy : 0.5971\n",
      "\n",
      "Epoch 610, Training loss: 1.256558\n",
      "Test accuracy : 0.5971\n",
      "\n",
      "Epoch 611, Training loss: 1.255225\n",
      "Test accuracy : 0.5973\n",
      "\n",
      "Epoch 612, Training loss: 1.253895\n",
      "Test accuracy : 0.5977\n",
      "\n",
      "Epoch 613, Training loss: 1.252568\n",
      "Test accuracy : 0.5978\n",
      "\n",
      "Epoch 614, Training loss: 1.251245\n",
      "Test accuracy : 0.5978\n",
      "\n",
      "Epoch 615, Training loss: 1.249925\n",
      "Test accuracy : 0.598\n",
      "\n",
      "Epoch 616, Training loss: 1.248608\n",
      "Test accuracy : 0.5982\n",
      "\n",
      "Epoch 617, Training loss: 1.247294\n",
      "Test accuracy : 0.5985\n",
      "\n",
      "Epoch 618, Training loss: 1.245984\n",
      "Test accuracy : 0.5985\n",
      "\n",
      "Epoch 619, Training loss: 1.244677\n",
      "Test accuracy : 0.5985\n",
      "\n",
      "Epoch 620, Training loss: 1.243373\n",
      "Test accuracy : 0.5986\n",
      "\n",
      "Epoch 621, Training loss: 1.242073\n",
      "Test accuracy : 0.5987\n",
      "\n",
      "Epoch 622, Training loss: 1.240776\n",
      "Test accuracy : 0.5991\n",
      "\n",
      "Epoch 623, Training loss: 1.239481\n",
      "Test accuracy : 0.5995\n",
      "\n",
      "Epoch 624, Training loss: 1.238191\n",
      "Test accuracy : 0.5998\n",
      "\n",
      "Epoch 625, Training loss: 1.236903\n",
      "Test accuracy : 0.6001\n",
      "\n",
      "Epoch 626, Training loss: 1.235619\n",
      "Test accuracy : 0.6006\n",
      "\n",
      "Epoch 627, Training loss: 1.234337\n",
      "Test accuracy : 0.6006\n",
      "\n",
      "Epoch 628, Training loss: 1.233059\n",
      "Test accuracy : 0.6007\n",
      "\n",
      "Epoch 629, Training loss: 1.231784\n",
      "Test accuracy : 0.6008\n",
      "\n",
      "Epoch 630, Training loss: 1.230513\n",
      "Test accuracy : 0.6013\n",
      "\n",
      "Epoch 631, Training loss: 1.229244\n",
      "Test accuracy : 0.6015\n",
      "\n",
      "Epoch 632, Training loss: 1.227979\n",
      "Test accuracy : 0.6019\n",
      "\n",
      "Epoch 633, Training loss: 1.226716\n",
      "Test accuracy : 0.6023\n",
      "\n",
      "Epoch 634, Training loss: 1.225457\n",
      "Test accuracy : 0.6025\n",
      "\n",
      "Epoch 635, Training loss: 1.224201\n",
      "Test accuracy : 0.6029\n",
      "\n",
      "Epoch 636, Training loss: 1.222948\n",
      "Test accuracy : 0.6029\n",
      "\n",
      "Epoch 637, Training loss: 1.221698\n",
      "Test accuracy : 0.6034\n",
      "\n",
      "Epoch 638, Training loss: 1.220452\n",
      "Test accuracy : 0.6034\n",
      "\n",
      "Epoch 639, Training loss: 1.219208\n",
      "Test accuracy : 0.6034\n",
      "\n",
      "Epoch 640, Training loss: 1.217967\n",
      "Test accuracy : 0.6036\n",
      "\n",
      "Epoch 641, Training loss: 1.216730\n",
      "Test accuracy : 0.6039\n",
      "\n",
      "Epoch 642, Training loss: 1.215496\n",
      "Test accuracy : 0.6041\n",
      "\n",
      "Epoch 643, Training loss: 1.214264\n",
      "Test accuracy : 0.6041\n",
      "\n",
      "Epoch 644, Training loss: 1.213036\n",
      "Test accuracy : 0.6042\n",
      "\n",
      "Epoch 645, Training loss: 1.211811\n",
      "Test accuracy : 0.6043\n",
      "\n",
      "Epoch 646, Training loss: 1.210589\n",
      "Test accuracy : 0.6044\n",
      "\n",
      "Epoch 647, Training loss: 1.209370\n",
      "Test accuracy : 0.6048\n",
      "\n",
      "Epoch 648, Training loss: 1.208154\n",
      "Test accuracy : 0.6052\n",
      "\n",
      "Epoch 649, Training loss: 1.206941\n",
      "Test accuracy : 0.6059\n",
      "\n",
      "Epoch 650, Training loss: 1.205731\n",
      "Test accuracy : 0.6062\n",
      "\n",
      "Epoch 651, Training loss: 1.204524\n",
      "Test accuracy : 0.6063\n",
      "\n",
      "Epoch 652, Training loss: 1.203320\n",
      "Test accuracy : 0.6067\n",
      "\n",
      "Epoch 653, Training loss: 1.202119\n",
      "Test accuracy : 0.607\n",
      "\n",
      "Epoch 654, Training loss: 1.200921\n",
      "Test accuracy : 0.6071\n",
      "\n",
      "Epoch 655, Training loss: 1.199726\n",
      "Test accuracy : 0.6074\n",
      "\n",
      "Epoch 656, Training loss: 1.198534\n",
      "Test accuracy : 0.6077\n",
      "\n",
      "Epoch 657, Training loss: 1.197345\n",
      "Test accuracy : 0.6081\n",
      "\n",
      "Epoch 658, Training loss: 1.196159\n",
      "Test accuracy : 0.6082\n",
      "\n",
      "Epoch 659, Training loss: 1.194976\n",
      "Test accuracy : 0.6083\n",
      "\n",
      "Epoch 660, Training loss: 1.193796\n",
      "Test accuracy : 0.6083\n",
      "\n",
      "Epoch 661, Training loss: 1.192619\n",
      "Test accuracy : 0.6084\n",
      "\n",
      "Epoch 662, Training loss: 1.191445\n",
      "Test accuracy : 0.6089\n",
      "\n",
      "Epoch 663, Training loss: 1.190274\n",
      "Test accuracy : 0.6092\n",
      "\n",
      "Epoch 664, Training loss: 1.189105\n",
      "Test accuracy : 0.6094\n",
      "\n",
      "Epoch 665, Training loss: 1.187940\n",
      "Test accuracy : 0.6103\n",
      "\n",
      "Epoch 666, Training loss: 1.186778\n",
      "Test accuracy : 0.6106\n",
      "\n",
      "Epoch 667, Training loss: 1.185618\n",
      "Test accuracy : 0.6106\n",
      "\n",
      "Epoch 668, Training loss: 1.184462\n",
      "Test accuracy : 0.6109\n",
      "\n",
      "Epoch 669, Training loss: 1.183308\n",
      "Test accuracy : 0.6111\n",
      "\n",
      "Epoch 670, Training loss: 1.182157\n",
      "Test accuracy : 0.6114\n",
      "\n",
      "Epoch 671, Training loss: 1.181009\n",
      "Test accuracy : 0.6114\n",
      "\n",
      "Epoch 672, Training loss: 1.179865\n",
      "Test accuracy : 0.6114\n",
      "\n",
      "Epoch 673, Training loss: 1.178723\n",
      "Test accuracy : 0.6111\n",
      "\n",
      "Epoch 674, Training loss: 1.177583\n",
      "Test accuracy : 0.6112\n",
      "\n",
      "Epoch 675, Training loss: 1.176447\n",
      "Test accuracy : 0.6118\n",
      "\n",
      "Epoch 676, Training loss: 1.175314\n",
      "Test accuracy : 0.612\n",
      "\n",
      "Epoch 677, Training loss: 1.174183\n",
      "Test accuracy : 0.612\n",
      "\n",
      "Epoch 678, Training loss: 1.173056\n",
      "Test accuracy : 0.6121\n",
      "\n",
      "Epoch 679, Training loss: 1.171931\n",
      "Test accuracy : 0.6121\n",
      "\n",
      "Epoch 680, Training loss: 1.170809\n",
      "Test accuracy : 0.6122\n",
      "\n",
      "Epoch 681, Training loss: 1.169690\n",
      "Test accuracy : 0.6125\n",
      "\n",
      "Epoch 682, Training loss: 1.168574\n",
      "Test accuracy : 0.6126\n",
      "\n",
      "Epoch 683, Training loss: 1.167461\n",
      "Test accuracy : 0.6129\n",
      "\n",
      "Epoch 684, Training loss: 1.166350\n",
      "Test accuracy : 0.6134\n",
      "\n",
      "Epoch 685, Training loss: 1.165243\n",
      "Test accuracy : 0.6138\n",
      "\n",
      "Epoch 686, Training loss: 1.164138\n",
      "Test accuracy : 0.6137\n",
      "\n",
      "Epoch 687, Training loss: 1.163036\n",
      "Test accuracy : 0.6139\n",
      "\n",
      "Epoch 688, Training loss: 1.161937\n",
      "Test accuracy : 0.6137\n",
      "\n",
      "Epoch 689, Training loss: 1.160840\n",
      "Test accuracy : 0.614\n",
      "\n",
      "Epoch 690, Training loss: 1.159747\n",
      "Test accuracy : 0.6141\n",
      "\n",
      "Epoch 691, Training loss: 1.158656\n",
      "Test accuracy : 0.6143\n",
      "\n",
      "Epoch 692, Training loss: 1.157568\n",
      "Test accuracy : 0.6147\n",
      "\n",
      "Epoch 693, Training loss: 1.156483\n",
      "Test accuracy : 0.6148\n",
      "\n",
      "Epoch 694, Training loss: 1.155400\n",
      "Test accuracy : 0.6149\n",
      "\n",
      "Epoch 695, Training loss: 1.154321\n",
      "Test accuracy : 0.615\n",
      "\n",
      "Epoch 696, Training loss: 1.153244\n",
      "Test accuracy : 0.6152\n",
      "\n",
      "Epoch 697, Training loss: 1.152170\n",
      "Test accuracy : 0.6156\n",
      "\n",
      "Epoch 698, Training loss: 1.151099\n",
      "Test accuracy : 0.6157\n",
      "\n",
      "Epoch 699, Training loss: 1.150030\n",
      "Test accuracy : 0.6162\n",
      "\n",
      "Epoch 700, Training loss: 1.148965\n",
      "Test accuracy : 0.6164\n",
      "\n",
      "Epoch 701, Training loss: 1.147902\n",
      "Test accuracy : 0.6165\n",
      "\n",
      "Epoch 702, Training loss: 1.146841\n",
      "Test accuracy : 0.6165\n",
      "\n",
      "Epoch 703, Training loss: 1.145784\n",
      "Test accuracy : 0.6164\n",
      "\n",
      "Epoch 704, Training loss: 1.144729\n",
      "Test accuracy : 0.6165\n",
      "\n",
      "Epoch 705, Training loss: 1.143677\n",
      "Test accuracy : 0.6171\n",
      "\n",
      "Epoch 706, Training loss: 1.142628\n",
      "Test accuracy : 0.6175\n",
      "\n",
      "Epoch 707, Training loss: 1.141581\n",
      "Test accuracy : 0.6179\n",
      "\n",
      "Epoch 708, Training loss: 1.140538\n",
      "Test accuracy : 0.6183\n",
      "\n",
      "Epoch 709, Training loss: 1.139496\n",
      "Test accuracy : 0.6183\n",
      "\n",
      "Epoch 710, Training loss: 1.138458\n",
      "Test accuracy : 0.6184\n",
      "\n",
      "Epoch 711, Training loss: 1.137422\n",
      "Test accuracy : 0.6184\n",
      "\n",
      "Epoch 712, Training loss: 1.136389\n",
      "Test accuracy : 0.6183\n",
      "\n",
      "Epoch 713, Training loss: 1.135359\n",
      "Test accuracy : 0.6183\n",
      "\n",
      "Epoch 714, Training loss: 1.134331\n",
      "Test accuracy : 0.6191\n",
      "\n",
      "Epoch 715, Training loss: 1.133306\n",
      "Test accuracy : 0.6194\n",
      "\n",
      "Epoch 716, Training loss: 1.132284\n",
      "Test accuracy : 0.6196\n",
      "\n",
      "Epoch 717, Training loss: 1.131265\n",
      "Test accuracy : 0.6197\n",
      "\n",
      "Epoch 718, Training loss: 1.130248\n",
      "Test accuracy : 0.6197\n",
      "\n",
      "Epoch 719, Training loss: 1.129233\n",
      "Test accuracy : 0.62\n",
      "\n",
      "Epoch 720, Training loss: 1.128222\n",
      "Test accuracy : 0.62\n",
      "\n",
      "Epoch 721, Training loss: 1.127213\n",
      "Test accuracy : 0.6201\n",
      "\n",
      "Epoch 722, Training loss: 1.126206\n",
      "Test accuracy : 0.6202\n",
      "\n",
      "Epoch 723, Training loss: 1.125203\n",
      "Test accuracy : 0.6207\n",
      "\n",
      "Epoch 724, Training loss: 1.124202\n",
      "Test accuracy : 0.621\n",
      "\n",
      "Epoch 725, Training loss: 1.123203\n",
      "Test accuracy : 0.6214\n",
      "\n",
      "Epoch 726, Training loss: 1.122208\n",
      "Test accuracy : 0.6218\n",
      "\n",
      "Epoch 727, Training loss: 1.121215\n",
      "Test accuracy : 0.6218\n",
      "\n",
      "Epoch 728, Training loss: 1.120224\n",
      "Test accuracy : 0.622\n",
      "\n",
      "Epoch 729, Training loss: 1.119236\n",
      "Test accuracy : 0.6222\n",
      "\n",
      "Epoch 730, Training loss: 1.118251\n",
      "Test accuracy : 0.6221\n",
      "\n",
      "Epoch 731, Training loss: 1.117268\n",
      "Test accuracy : 0.6225\n",
      "\n",
      "Epoch 732, Training loss: 1.116288\n",
      "Test accuracy : 0.6228\n",
      "\n",
      "Epoch 733, Training loss: 1.115311\n",
      "Test accuracy : 0.623\n",
      "\n",
      "Epoch 734, Training loss: 1.114336\n",
      "Test accuracy : 0.6229\n",
      "\n",
      "Epoch 735, Training loss: 1.113363\n",
      "Test accuracy : 0.6231\n",
      "\n",
      "Epoch 736, Training loss: 1.112393\n",
      "Test accuracy : 0.623\n",
      "\n",
      "Epoch 737, Training loss: 1.111426\n",
      "Test accuracy : 0.6234\n",
      "\n",
      "Epoch 738, Training loss: 1.110462\n",
      "Test accuracy : 0.6235\n",
      "\n",
      "Epoch 739, Training loss: 1.109500\n",
      "Test accuracy : 0.6236\n",
      "\n",
      "Epoch 740, Training loss: 1.108540\n",
      "Test accuracy : 0.6238\n",
      "\n",
      "Epoch 741, Training loss: 1.107583\n",
      "Test accuracy : 0.6237\n",
      "\n",
      "Epoch 742, Training loss: 1.106629\n",
      "Test accuracy : 0.624\n",
      "\n",
      "Epoch 743, Training loss: 1.105677\n",
      "Test accuracy : 0.6246\n",
      "\n",
      "Epoch 744, Training loss: 1.104727\n",
      "Test accuracy : 0.6246\n",
      "\n",
      "Epoch 745, Training loss: 1.103780\n",
      "Test accuracy : 0.6248\n",
      "\n",
      "Epoch 746, Training loss: 1.102836\n",
      "Test accuracy : 0.6249\n",
      "\n",
      "Epoch 747, Training loss: 1.101894\n",
      "Test accuracy : 0.6252\n",
      "\n",
      "Epoch 748, Training loss: 1.100955\n",
      "Test accuracy : 0.6254\n",
      "\n",
      "Epoch 749, Training loss: 1.100018\n",
      "Test accuracy : 0.6257\n",
      "\n",
      "Epoch 750, Training loss: 1.099084\n",
      "Test accuracy : 0.6258\n",
      "\n",
      "Epoch 751, Training loss: 1.098152\n",
      "Test accuracy : 0.6259\n",
      "\n",
      "Epoch 752, Training loss: 1.097223\n",
      "Test accuracy : 0.6261\n",
      "\n",
      "Epoch 753, Training loss: 1.096296\n",
      "Test accuracy : 0.6262\n",
      "\n",
      "Epoch 754, Training loss: 1.095372\n",
      "Test accuracy : 0.6263\n",
      "\n",
      "Epoch 755, Training loss: 1.094450\n",
      "Test accuracy : 0.6266\n",
      "\n",
      "Epoch 756, Training loss: 1.093530\n",
      "Test accuracy : 0.6265\n",
      "\n",
      "Epoch 757, Training loss: 1.092613\n",
      "Test accuracy : 0.6265\n",
      "\n",
      "Epoch 758, Training loss: 1.091699\n",
      "Test accuracy : 0.6265\n",
      "\n",
      "Epoch 759, Training loss: 1.090787\n",
      "Test accuracy : 0.6267\n",
      "\n",
      "Epoch 760, Training loss: 1.089877\n",
      "Test accuracy : 0.6268\n",
      "\n",
      "Epoch 761, Training loss: 1.088970\n",
      "Test accuracy : 0.627\n",
      "\n",
      "Epoch 762, Training loss: 1.088065\n",
      "Test accuracy : 0.6271\n",
      "\n",
      "Epoch 763, Training loss: 1.087163\n",
      "Test accuracy : 0.6274\n",
      "\n",
      "Epoch 764, Training loss: 1.086263\n",
      "Test accuracy : 0.6276\n",
      "\n",
      "Epoch 765, Training loss: 1.085365\n",
      "Test accuracy : 0.6278\n",
      "\n",
      "Epoch 766, Training loss: 1.084470\n",
      "Test accuracy : 0.6277\n",
      "\n",
      "Epoch 767, Training loss: 1.083578\n",
      "Test accuracy : 0.6278\n",
      "\n",
      "Epoch 768, Training loss: 1.082688\n",
      "Test accuracy : 0.6279\n",
      "\n",
      "Epoch 769, Training loss: 1.081800\n",
      "Test accuracy : 0.6281\n",
      "\n",
      "Epoch 770, Training loss: 1.080914\n",
      "Test accuracy : 0.6281\n",
      "\n",
      "Epoch 771, Training loss: 1.080031\n",
      "Test accuracy : 0.6282\n",
      "\n",
      "Epoch 772, Training loss: 1.079150\n",
      "Test accuracy : 0.6285\n",
      "\n",
      "Epoch 773, Training loss: 1.078272\n",
      "Test accuracy : 0.6286\n",
      "\n",
      "Epoch 774, Training loss: 1.077396\n",
      "Test accuracy : 0.6285\n",
      "\n",
      "Epoch 775, Training loss: 1.076522\n",
      "Test accuracy : 0.6287\n",
      "\n",
      "Epoch 776, Training loss: 1.075651\n",
      "Test accuracy : 0.6289\n",
      "\n",
      "Epoch 777, Training loss: 1.074782\n",
      "Test accuracy : 0.6292\n",
      "\n",
      "Epoch 778, Training loss: 1.073916\n",
      "Test accuracy : 0.6291\n",
      "\n",
      "Epoch 779, Training loss: 1.073051\n",
      "Test accuracy : 0.6293\n",
      "\n",
      "Epoch 780, Training loss: 1.072189\n",
      "Test accuracy : 0.6291\n",
      "\n",
      "Epoch 781, Training loss: 1.071330\n",
      "Test accuracy : 0.6294\n",
      "\n",
      "Epoch 782, Training loss: 1.070473\n",
      "Test accuracy : 0.6295\n",
      "\n",
      "Epoch 783, Training loss: 1.069618\n",
      "Test accuracy : 0.6296\n",
      "\n",
      "Epoch 784, Training loss: 1.068765\n",
      "Test accuracy : 0.6298\n",
      "\n",
      "Epoch 785, Training loss: 1.067915\n",
      "Test accuracy : 0.6301\n",
      "\n",
      "Epoch 786, Training loss: 1.067067\n",
      "Test accuracy : 0.6299\n",
      "\n",
      "Epoch 787, Training loss: 1.066221\n",
      "Test accuracy : 0.6303\n",
      "\n",
      "Epoch 788, Training loss: 1.065377\n",
      "Test accuracy : 0.6304\n",
      "\n",
      "Epoch 789, Training loss: 1.064536\n",
      "Test accuracy : 0.6305\n",
      "\n",
      "Epoch 790, Training loss: 1.063697\n",
      "Test accuracy : 0.6306\n",
      "\n",
      "Epoch 791, Training loss: 1.062860\n",
      "Test accuracy : 0.6308\n",
      "\n",
      "Epoch 792, Training loss: 1.062026\n",
      "Test accuracy : 0.6308\n",
      "\n",
      "Epoch 793, Training loss: 1.061194\n",
      "Test accuracy : 0.6311\n",
      "\n",
      "Epoch 794, Training loss: 1.060364\n",
      "Test accuracy : 0.6313\n",
      "\n",
      "Epoch 795, Training loss: 1.059536\n",
      "Test accuracy : 0.6313\n",
      "\n",
      "Epoch 796, Training loss: 1.058711\n",
      "Test accuracy : 0.6317\n",
      "\n",
      "Epoch 797, Training loss: 1.057888\n",
      "Test accuracy : 0.6317\n",
      "\n",
      "Epoch 798, Training loss: 1.057067\n",
      "Test accuracy : 0.6316\n",
      "\n",
      "Epoch 799, Training loss: 1.056248\n",
      "Test accuracy : 0.6316\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def train(X_train, Y_train, X_test, Y_test, epochs=10, learning_rate=0.01, activation='relu'):\n",
    "    np.random.seed(1) \n",
    "    nn = NeuralNetwork([X_train.shape[0], 64, 10], activation)\n",
    "    traing_loss, test_accuracy = [], []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        HL, caches = nn.forward_propagation(X_train)\n",
    "        loss = nn.compute_loss(Y_train, HL)\n",
    "        grads = nn.backpropagation(X_train, Y_train, caches)\n",
    "        nn.update_parameters(grads, learning_rate)\n",
    "        \n",
    "        if epoch % 1 == 0:\n",
    "            print(\"Epoch %i, Training loss: %f\" % (epoch, loss))\n",
    "    \n",
    "            # Evaluate model on whole test data after each epoch\n",
    "            predictions, _ = nn.forward_propagation(X_test)\n",
    "            accuracy = np.mean(np.argmax(predictions, axis=0) == np.argmax(Y_test, axis=0))\n",
    "            print(f\"Test accuracy : {accuracy}\\n\")\n",
    "\n",
    "            traing_loss.append(loss)\n",
    "            test_accuracy.append(accuracy)\n",
    "    \n",
    "    plot_training_loss_and_test_acc(epochs, traing_loss, test_accuracy)\n",
    "X_train, Y_train, X_test, Y_test = preprocess_data(train_images, train_labels, test_images, test_labels)\n",
    "train(X_train, Y_train, X_test, Y_test, epochs=800, activation='relu', learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d6bebf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
